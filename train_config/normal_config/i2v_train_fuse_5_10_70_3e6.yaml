# model:
model_config_path: "/data/user/hongfeizhang/hongfei_workspace/DiffSynth-Studio/model_config/controlnet_gate_asym_5_10.yaml"
model_id_with_origin_paths: "PAI/Wan2.1-Fun-V1.1-1.3B-Control-Camera:diffusion_pytorch_model*.safetensors,PAI/Wan2.1-Fun-V1.1-1.3B-Control-Camera:models_t5_umt5-xxl-enc-bf16.pth,PAI/Wan2.1-Fun-V1.1-1.3B-Control-Camera:Wan2.1_VAE.pth,PAI/Wan2.1-Fun-V1.1-1.3B-Control-Camera:models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth"
pipe_name: "wan_video_camera"
training_state_dir: '/data/user/hongfeizhang/experiments/Wan/09-10-14-36-train-depth-I2V-480p-mask-depth-loss/checkpoint-step-2000'
output_path: "/data/user/hongfeizhang/experiments/Wan/11-18-train-fuse-I2V-480-mask-depth-30-3e6-5-10"

# Trainable models
trainable_models: "dit"
remove_prefix_in_ckpt: "pipe.dit"
freeze_main_except: "all"        # [none, lora, all]
has_control_model: true
freeze_control_except: "all"     # [none, lora, all]
copy_control_weights: false
freeze_zero_linear: false

# LoRA / checkpoint (we don't use lora here so there's need to implement)
ckpt_has_lora: false
ckpt_lora_base_model: null
ckpt_lora_module: ""
ckpt_lora_rank: 0
ckpt_lora_adapter_name: "default"

add_lora: false
lora_base_model: null
lora_target_modules: ""
lora_adapter_name: "control"
lora_rank: 0


# train:
t2v: false
num_epochs: 1000000
learning_rate: 3e-6
validate_step: 400
log_step: 50
use_gradient_checkpointing: true
no_extra_frame: true # you may use this param with complementation like SEVA's M-in-N-out schema
warmup_steps: 0
return_control_latents: true
drop_loss_rate: 30

# validate 
init_validate: true
validate_batch: 16


# dataset:
dataset_name: "re10k"   # [re10k, dl3dv]

# Re10k
batch_size: 1
train_height: 480
train_width: 720
use_image_depth: false

# optimizer:
load_optimizer: false
