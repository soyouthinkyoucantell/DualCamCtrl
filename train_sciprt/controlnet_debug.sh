accelerate launch --config_file accelerate.yaml -m examples.wanvideo.model_training.train_with_accelerate \
  --model_config_path '/hpc2hdd/home/hongfeizhang/hongfei_workspace/DiffSynth-Studio/model_config/controlnet_config.yaml' \
  --training_state_dir '/hpc2hdd/home/hongfeizhang/experiments/Wan_Debug/debug' \
  --height 480 \
  --width 832 \
  --output_path '/hpc2hdd/home/hongfeizhang/experiments/Wan_Debug/debug_1' \
  --model_id_with_origin_paths "PAI/Wan2.1-Fun-V1.1-1.3B-InP:diffusion_pytorch_model*.safetensors,PAI/Wan2.1-Fun-V1.1-1.3B-InP:models_t5_umt5-xxl-enc-bf16.pth,PAI/Wan2.1-Fun-V1.1-1.3B-InP:Wan2.1_VAE.pth,PAI/Wan2.1-Fun-V1.1-1.3B-InP:models_clip_open-clip-xlm-roberta-large-vit-huge-14.pth" \
  --learning_rate 1e-5 \
  --num_epochs 50 \
  --remove_prefix_in_ckpt "pipe.dit." \
  --trainable_models "dit" \
  --validate_step 2 \
  --use_gradient_checkpointing